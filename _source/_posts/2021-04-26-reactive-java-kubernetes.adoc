---
layout: blog_post
title: "Git Yer Java Microservices to the Cloud with K8s and Spring Boot"
# title: "Git to the Cloud with K8s and Spring Boot"
# title: "Git to Google Cloud with K8s and Spring Boot"
author: matt-raible
by: advocate
communities: [devops,java]
description: "Giddyup and go into the cloud!"
tags: []
tweets:
- ""
- ""
- ""
image:
type: conversion
---
:page-liquid:
:toc: macro
:experimental:

When your business or application is successful, it needs to scale. Not just technology-wise, but human-wise. When you're growing rapidly, it can be difficult to hire developers fast enough. Using a microservices architecture for your apps can allow you to divide up ownership, responsibilities, and scale teams with your code.

Spring Boot and Spring Cloud were some of the pioneering frameworks in Javaland. However, even they stood on the shoulders of giants when they leveraged Netflix open source projects to embrace and extend. In 2018, https://netflixtechblog.com/netflix-oss-and-spring-boot-coming-full-circle-4855947713a0[Netflix OSS announced they'd come full circle], and adopted Spring Boot.

Today, I'd like to show you how to build a __reactive__ microservice architecture with Spring Boot, Spring Cloud, and JHipster. Why reactive? Because Spring Cloud Gateway is now the default for JHipster 7, even if you choose to build your microservices with Spring MVC.

Spring Cloud Gateway is a library for building an API Gateway on top of Spring WebFlux. It makes it easy to integrate OAuth in to communicate between microservices. You just need to add a `TokenRelay` filter.

[source,yaml]
----
spring:
  cloud:
    gateway:
      default-filters:
        - TokenRelay
----

CAUTION: Netflix Zuul is no longer supported by Spring Cloud. There is an https://github.com/spring-cloud/spring-cloud-gateway/issues/36[open issue] to add Spring MVC/Servlet support to Spring Cloud Gateway.

**Prerequisites**

- https://sdkman.io/[Java 11]+
- https://nodejs.org/[Node.js]
- https://docs.docker.com/get-docker/[Docker]
- A https://cloud.google.com/[Google Cloud] Account

toc::[]

== A Brief Intro to Kubernetes (K8s)

Kubernetes is an open source project from Google that provides an API for deploying your apps and making them talk with each other. It helps automate deployments, updates, and managing your apps and services with limited downtime. You use Docker containers and YAML to make it all work.

The YAML can be hideous, but that's where JHipster comes in. It can generate the YAML for you!

== Create a Kubernetes-Ready Microservices Architecture

I showed you how to build https://developer.okta.com/blog/2021/01/20/reactive-java-microservices[Reactive Java microservices with Spring Boot and JHipster] in a previous post. Today I'll show you how to generate K8s deployment descriptors, use Spring Cloud Config with Git, encrypt your secrets, and make it all work on Google Cloud (https://cloud.google.com/kubernetes-engine/[GKE] to be specific).

Start by cloning the JHipster 7 { Vue, Spring Boot, WebFlux } app from GitHub:

[source,shell]
----
git clone https://github.com/oktadeveloper/java-microservices-examples.git
cd java-microservices-examples/reactive-jhipster
----

[TIP]
====
If you just want to see the completed project, just cd into the project's `jhipster-k8s` directory.

[source,shell]
----
cd ../jhipster-k8s
----
====

This project has four directories:

- `gateway`: a Spring Boot + Spring Cloud Gateway project configured for OpenID Connect (OIDC) login. It's also configured as an OAuth 2.0 resource server. It contains a front end application that's built with Vue.
- `blog`: a Spring Boot + WebFlux microservice that talks to a Neo4j database.
- `store`: a Spring Boot + WebFlux microservice that uses MongoDB.
- `docker-compose`: a set of Docker files that describe how to run all containers together.

NOTE: The SPA app on the gateway is currently a monolith. The JHipster team is still working on https://github.com/jhipster/generator-jhipster/issues/10189[micro frontends support].

Once you've configured OIDC, you'll use Docker Compose to run everything.

Now that you have the project cloned, use JHipster to add Kubernetes support.

If you don't have JHipster installed, install it.

[source,shell]
----
npm i -g generator-jhipster@7
----

== Create a Container Registry on Google Cloud

Before the JHipster 7.0.0 release, I tested this microservice example with Kubernetes and Google Cloud. Ray Tsang's https://spring-gcp.saturnism.me/[Spring Boot on GCP Guides] where a https://twitter.com/mraible/status/1372964263237718026[huge help]!

// todo: move this somewhere else as it's kinda in the way

++++
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">I re-created this example with the latest code from <a href="https://twitter.com/jhipster?ref_src=twsrc%5Etfw">@jhipster</a>&#39;s main branch this week and deployed it to <a href="https://twitter.com/googlecloud?ref_src=twsrc%5Etfw">@googlecloud</a> with <a href="https://twitter.com/kubernetesio?ref_src=twsrc%5Etfw">@kubernetesio</a>. <br><br>I&#39;m happy to report I was able to get everything working! <a href="https://twitter.com/saturnism?ref_src=twsrc%5Etfw">@saturnism</a>&#39;s Spring Boot on GCP docs was a big help. üôè<a href="https://t.co/NBGj0OAOxM">https://t.co/NBGj0OAOxM</a> <a href="https://t.co/k1mm4e1fr8">https://t.co/k1mm4e1fr8</a></p>&mdash; Matt Raible (@mraible) <a href="https://twitter.com/mraible/status/1372964263237718026?ref_src=twsrc%5Etfw">March 19, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
++++

https://spring-gcp.saturnism.me/getting-started/google-cloud-platform[Sign up for Google Cloud Platform (GCP)], log in, and create a project. Open a https://console.cloud.google.com/[console] in your browser. A GCP project contains all cloud services and resources--such as virtual machines, network, load balancers--that you might use.

TIP: You can also download and install the https://cloud.google.com/sdk/[`gcloud` CLI] if you want to run things locally.

Enable the Google Kubernetes Engine API:

[source,shell]
----
gcloud services enable container.googleapis.com containerregistry.googleapis.com
----

Install `kubectl` CLI:

[source,shell]
----
gcloud components install kubectl
----

Run the following command to create a cluster for your apps.

[[create-cluster]]
[source,shell]
----
gcloud container clusters create CLUSTER_NAME \
--zone us-central1-a \
--machine-type n1-standard-4 \
--enable-autorepair \
--enable-autoupgrade
----

I called mine `reactive-ms`. See GCP's https://cloud.google.com/compute/docs/regions-zones/[zones] and https://cloud.google.com/compute/docs/machine-types/[machine-types] for other options. I found the `n1-standard-4` to be the minimum for JHipster.

== Generate Kubernetes Deployment Descriptors

Navigate to the `reactive-jhipster` directory. Create a `k8s` directory, cd into it, and run JHipster's https://www.jhipster.tech/kubernetes/[Kubernetes sub-generator].

[source,shell]
----
mkdir k8s
jhipster k8s
----

You'll be prompted with a number of questions. Answer them as I did below.

- Type of application: **Microservice application**
- Root directory: **../**
- Which applications? <select all>
- Set up monitoring? **No**
- Which applications with clustered databases? select **store**
- Admin password for JHipster Registry: <generate one>
- Kubernetes namespace: **default**
- Docker repository name: `gcr.io/YOUR_GCP_PROJECT_ID`
- Command to push Docker image: `docker push`
- Enable Istio? **No**
- Kubernetes service type? **LoadBalancer**
- Use dynamic storage provisioning? **Yes**
- Use a specific storage class? <leave empty>

image::{% asset_path 'blog/reactive-java-kubernetes/jhipster-k8s.png' %}[alt=JHipster K8s command with answers,width=800,align=center]

Notice that I'm using `gcr.io/jhipster7` for my Docker repository name.

After I answered these questions, my `k8s/.yo-rc.json` file had the following contents:

[source,json]
----
{
  "generator-jhipster": {
    "appsFolders": ["blog", "gateway", "store"],
    "directoryPath": "../",
    "clusteredDbApps": ["store"],
    "serviceDiscoveryType": "eureka",
    "dockerRepositoryName": "gcr.io/jhipster7",
    "dockerPushCommand": "docker push",
    "kubernetesNamespace": "default",
    "kubernetesServiceType": "LoadBalancer",
    "kubernetesUseDynamicStorage": false,
    "kubernetesStorageClassName": "",
    "ingressDomain": "",
    "monitoring": "no",
    "istio": false
  }
}
----

Create Docker images for each app. In the {`gateway`, `blog`, `store` } directories, run the following Gradle command:

[source,shell]
----
./gradlew -Pprod bootJar jibDockerBuild
----

=== Register an OIDC App for Auth

You've built Docker images for your microservices, but you haven't seen them running. First, you'll need to configure Okta for authentication and authorization.

{% include setup/cli.md type="jhipster" %}

JHipster ships with https://www.jhipster.tech/jhipster-registry/[JHipster Registry]. It acts as a Eureka service for service discovery, and contains a Spring Cloud Config server for distributing your configuration settings.

Update `docker-compose/central-server-config/application.yml` to contain your OIDC settings from the `.okta.env` file the Okta CLI just created. The Spring Cloud Config server reads from this file and shares the values with the gateway and microservices.

[source,yaml]
----
spring:
  security:
    oauth2:
      client:
        provider:
          oidc:
            issuer-uri: https://<your-okta-domain>/oauth2/default
        registration:
          oidc:
            client-id: <client-id>
            client-secret: <client-secret>
----

Then, in the `docker-compose` directory, start your engines!

[source,shell]
----
docker-compose up
----

You can see if everything started up OK at `\http://localhost:8761`. You'll need to sign in with your Okta credentials.

Once all is green, go to `\http://localhost:8080` and you should be able to add blogs, posts, tags, and products.

You can also automate testing that everything works. Set your Okta credentials as environment variables and run end-to-end tests (from the gateway directory).

[source,shell]
----
export CYPRESS_E2E_USERNAME=<your-username>
export CYPRESS_E2E_PASSWORD=<your-password>
npm run e2e
----

Proof it worked for me:

image::{% asset_path 'blog/reactive-java-kubernetes/cypress-e2e.png' %}[alt=Cypress end-to-end tests,width=800,align=center]

=== Why Not Istio?

I didn't use Istio in this example because I didn't want to complicate things. Learning Kubernetes is hard enough without learning another system on top of it. Istio acts as a network between your containers that's able to do networky things like authentication, authorization, monitoring, and retries. I like to think of it as AOP for containers.

I recently listened to The New Stack's Podcast episode, https://thenewstack.io/which-comes-first-istio-or-kubernetes/[Which Comes First: Istio or Kubernetes?]. It talks to https://www.linkedin.com/in/varuntalwar/[Varun Talwar] and https://www.linkedin.com/in/zack-butcher-339a2180[Zack Butcher],
creators of Istio. I like how they'd eventually like to make services meshes so boring that everyone uses them and developers don't have to worry about it.

If you'd like to see how to use JHipster with Istio, see https://dev.to/deepu105/how-to-set-up-java-microservices-with-istio-service-mesh-on-kubernetes-5bkn[How to set up Java microservices with Istio service mesh on Kubernetes] by JHipster co-lead https://twitter.com/deepu105[Deepu K Sasidharan].

=== Plain Text Secrets? Uggh!

You might notice I used a secret in plain text in the `application.yml` file. This is a bad practice! I hope you didn't check everything into source control yet!!

== Encrypt / Decrypt Your Spring Cloud Configuration

The JHipster Registry has an encryption mechanism you can use to encrypt your secrets. That way, it's a bit safer to store them in public repositories. Create a `docker-compose/.env` file and specify an `ENCRYPT_KEY` in it. Make sure `*.env` is in your `.gitignore` file while you're at it!

[source,dotenv]
----
ENCRYPT_KEY=really-long-string-of-random-charters-that-you-can-keep-safe
----

[TIP]
====
You can use JShell to generate a UUID you can use for your encrypt key.

[source,shell]
----
jhsell

UUID.randomUUID()
----

image::{% asset_path 'blog/reactive-java-kubernetes/jshell-uuid.png' %}[alt=JShell UUID,width=780,align=center]

You can quit by typing `/exit`.
====

Then, update `docker-compose.yml` to set this value as an environment variable.

[source,yaml]
----
jhipster-registry:
  ...
  environment:
    - _JAVA_OPTIONS=-Xmx512m -Xms256m
    - JHIPSTER_SLEEP=20
    - SPRING_PROFILES_ACTIVE=dev,oauth2
    - SPRING_SECURITY_USER_PASSWORD=admin
    - JHIPSTER_REGISTRY_PASSWORD=*******
    - ENCRYPT_KEY=${ENCRYPT_KEY}
----

Stop all your containers using kbd:[Ctrl + C] or run `docker-compose down`. Start all your containers again.

[source,shell]
----
docker-compose up
----

=== Encrypt Your OIDC Client Secret

You can encrypt your client secret by logging into `http://localhost:8761` and going to **Configuration** > **Encryption**.

Copy and paste your client secret from `application.yml` (or `gateway/.okta.env`) and click **Encrypt**.

image::{% asset_path 'blog/reactive-java-kubernetes/registry-encrypt.png' %}[alt=JHipster Registry Encrypt Feature,width=800,align=center]

Then, copy the encrypted value back in to `application.yml`. Make sure to wrap it in quotes!

You can also use curl:

[source,shell]
----
curl -X POST http://admin:admin@localhost:8761/config/encrypt -d your-client-secret
----

If you use curl, make sure to add `{cipher}` to the beginning of the string. For example:

[source,yaml]
----
client-secret: "{cipher}1b12934716c32d360c85f651a0793df2777090c..."
----

Restart the JHipster Registry for the new values to take effect.

[source,shell]
----
docker-compose stop jhipster-registry
docker-compose start jhipster-registry
----

Verify everything still works at `http://localhost:8080`.

TIP: If you want to make it so you don't need to restart the Spring Cloud Config server when you `git push`, see https://developer.okta.com/blog/2020/12/07/spring-cloud-config#refresh-the-configuration-in-your-spring-cloud-config-server[Refresh the Configuration in Your Spring Cloud Config Server].

== Change Spring Cloud Config Server to use Git

You might want to store your app's configuration externally. That way, you don't have to redeploy everything to change values. Good news! Spring Cloud Config makes it easy to switch to Git instead of the filesystem to store your configuration.

In `docker-compose.yml`, replace the following variables:

[source,yaml]
----
- SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_0_TYPE=native
- SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_0_SEARCH_LOCATIONS=file:./central-config
----

With values for a GitHub repo.

[source,yaml]
----
- SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_0_TYPE=git
- SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_0_URI=https://github.com/mraible/reactive-java-ms-config/
- SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_0_SEARCH_PATHS=config
- SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_0_LABEL=main
----

Make sure to change the URI to your repo, or you'll be using my OIDC app!

See Spring Cloud Config's https://cloud.spring.io/spring-cloud-config/multi/multi__spring_cloud_config_server.html#_git_backend[Git Backend docs] for more information.

== Deploy to Google Cloud (aka GCP)

Now it's time to go to the moon! Errr... cloud.

You created Docker images earlier to run with Docker Compose. Those images were deployed to your local Docker registry. For Google Cloud and its Kubernetes engine (GKE), you'll need to publish your images to your project's registry. Thankfully, this is easy to do with Jib.

Navigate to the `gateway` directory and run:

[source,shell]
----
./gradlew bootJar -Pprod jib -Djib.to.image=gcr.io/<your-project-id>/gateway
----

Repeat the process for `blog` and `store`. You can run these processes in parallel to speed things up. Make sure to change the image name at the end of each command.

[source,shell]
----
cd ../blog
./gradlew bootJar -Pprod jib -Djib.to.image=gcr.io/<your-project-id>/blog
cd ../store
./gradlew bootJar -Pprod jib -Djib.to.image=gcr.io/<your-project-id>/store
----

TIP: You might have to run `gcloud auth configure-docker` for Jib to publish to your GCP container registry.

In the `k8s` directory, apply all the deployment descriptors to deploy all your images.

[source,shell]
----
bash kubectl-apply.sh -f
----

TIP: If you get an error about connecting to the server at `127.0.0.1:64317`, it's because you haven't <<create-cluster,created a cluster>> yet.

You can monitor the progress of your deployments with `kubectl get pods`. You'll likely see a number of pods have restarted several times. This is because there's no Keycloak instance deployed and it's trying to connect.

=== Configure Your Kubernetes Cluster for OIDC

First, I'm going to show you the _wrong_ way to configure your deployments to work with Okta. I'm showing you this way because it's fast and it's fun to see things running. Why is it wrong? Because you're storing secrets in files that might be checked into source control.

Edit `k8s/registry-k8s/jhipster-registry.yml` and add your OIDC settings to the `env` key. You should be able to get these values from `gateway/.okta.env`.

[source,yaml]
----
- name: SPRING_SECURITY_OAUTH2_CLIENT_PROVIDER_OIDC_ISSUER_URI
  value: "https://{yourOktaDomain}/oauth2/default"
- name: SPRING_SECURITY_OAUTH2_CLIENT_REGISTRATION_OIDC_CLIENT_ID
  value: "{yourClientId}"
- name: SPRING_SECURITY_OAUTH2_CLIENT_REGISTRATION_OIDC_CLIENT_SECRET
  value: "{yourClientSecret}"
----

Add these same values to the `*-deployment.yml` files in `blog-k8s`, `gateway-k8s`, and `store-k8s`. Run `./kubectl-apply.sh -f` again.

Once everything is up and running, get the external IP of your gateway.

[source,shell]
----
kubectl get svc gateway
----

You'll need to add the external IP address as a valid redirect to your Okta OIDC app. Run `okta login`, open the returned URL in your browser, and sign in to the Okta Admin Console. Go to the **Applications** section, find your application, and edit it.

Add the standard JHipster redirect URIs using the IP address. For example, `\http://34.71.48.244:8080/login/oauth2/code/oidc` for the login redirect URI and `\http://34.71.48.244:8080` for the logout redirect URI.

You can use the following command to set your gateway's IP address as a variable you can curl.

[source,shell]
----
EXTERNAL_IP=$(kubectl get svc gateway -ojsonpath="{.status.loadBalancer.ingress[0].ip}")
curl $EXTERNAL_IP:8080
----

Open `\http://$EXTERNAL_IP:8080` in a browser, and you should be able to sign in.

image::{% asset_path 'blog/reactive-java-kubernetes/gke-first-login.png' %}[alt=First log in on GKE,width=800,align=center]

Great! Now you know things work, let's integrate better security, starting with HTTPS.

=== Add HTTPS

You should always use HTTPS. It's one of the easiest ways to secure things, especially with the free certificates offered these days.

Ray Tsang's https://spring-gcp.saturnism.me/deployment/kubernetes/load-balancing/external-load-balancing[External Load Balancing docs] was a big help in figuring out all these steps.

You'll need a static IP you can assign your TLS (the official name for HTTPS) certificate too.

[source,shell]
----
gcloud compute addresses create gateway-ingress-ip --global
----

You can run the following command to make sure it worked.

[source,shell]
----
gcloud compute addresses describe gateway-ingress-ip --global --format='value(address)'
----

Then, create a `k8s/ingress.yml` file:

[source,yaml]
----
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: gateway
  annotations:
    kubernetes.io/ingress.global-static-ip-name: "gateway-ingress-ip"
spec:
  rules:
  - http:
      paths:
      - path: /*
        backend:
          serviceName: gateway
          servicePort: 8080
----

Deploy it and make sure it worked.

[source,shell]
----
kubectl apply -f ingress.yml

# wait until this command displays an IP address
kubectl get ingress gateway
----

In order to use a TLS certificate, you must have a fully qualified domain name and configure it to point to the IP address. If you don't have a real domain, you can use https://nip.io/[nip.io].

Set the IP in a variable, as well as the domain.

[source,shell]
----
EXTERNAL_IP=$(kubectl get ingress gateway -ojsonpath="{.status.loadBalancer.ingress[0].ip}")
DOMAIN="${EXTERNAL_IP}.nip.io"

# Prove it works
echo $DOMAIN
curl $DOMAIN
----

To create a certificate, create a `k8s/certificate.yml` file. Make sure to replace the `${DOMAIN}` with your domain.

[source,shell]
----
cat << EOF > certificate.yml
apiVersion: networking.gke.io/v1beta2
kind: ManagedCertificate
metadata:
  name: gateway-certificate
spec:
  domains:
  # Replace the value with your domain name
  - ${DOMAIN}
EOF
----

Add the certificate to `ingress.yml`:

[source,yaml]
----
...
metadata:
  name: gateway
  annotations:
    kubernetes.io/ingress.global-static-ip-name: "gateway-ingress-ip"
    networking.gke.io/managed-certificates: "gateway-certificate"
...
----

Deploy both files:

[source,shell]
----
kubectl apply -f certificate.yml
kubectl apply -f ingress.yml
----

Check your certificate's status until it prints `Status: ACTIVE`:

[source,shell]
----
kubectl describe managedcertificate gateway-certificate
----

While you're waiting, you can proceed to forcing HTTPS in the next step.

=== Force HTTPS with Spring Security

Spring Security's WebFlux support makes it easy to https://docs.spring.io/spring-security/site/docs/5.5.x/reference/html5/#webflux-http-redirect[redirect to HTTPS]. However, if you redirect _all_ HTTPS requests, the Kubernetes health checks will fail because they receive a 302 instead of a 200.

Crack open `SecurityConfiguration.java` in the gateway project and add the following code to the `springSecurityFilterChain()` method.

[source,java]
.src/main/java/.../gateway/config/SecurityConfiguration.java
----
http.redirectToHttps(redirect -> redirect
    .httpsRedirectWhen(e -> e.getRequest().getHeaders().containsKey("X-Forwarded-Proto"))
);
----

Rebuild the Docker image for the gateway project.

[source,shell]
----
./gradlew bootJar -Pprod jib -Djib.to.image=gcr.io/<your-project-id>/gateway
----

Run the following commands to start a rolling restart of gateway instances.

[source,shell]
----
kubectl rollout restart deployment gateway
----

TIP: Run `kubectl get deployments` to see your deployment names.

Run `kubectl get pods` to see your gateway pods restarting. You can use the name of a pod in the following command to tail its logs.

[source,shell]
----
kubectl logs <pod-name> --tail=-1
----

Now you should get a 302 when you access your domain. https://httpie.io/[HTTPie] is a useful alternative to curl.

image::{% asset_path 'blog/reactive-java-kubernetes/httpie-302.png' %}[alt=302 in HTTPie,width=800,align=center]

Update your Okta OIDC app to have `$EXTERNAL_IP.nip.io` as a valid redirect URI.

== Keeping Kubernetes Secrets

Congratulations, now you have everything running on GKE, using HTTPS! However, you took a couple shortcuts:

. You configured each app with environment variables for OIDC, rather than looking them up from Spring Cloud Config.
. The JHipster Registry is not configured to read from GitHub like you previously configured.
. You have a lot of plain-text secrets in your K8s YAML files.

"But, wait!" you might say. Doesn't https://kubernetes.io/docs/concepts/configuration/secret/[Kubernetes Secrets] solve everything?

In my opinion, no. They're just unencrypted base64-encoded strings stored in YAML files. You probably want to check in the `k8s` directory you created.

Having secrets in your source code is a bad idea. The good news is most people (where people are my followers) manage secrets externally.

++++
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">What&#39;s your favorite way to protect secrets in your <a href="https://twitter.com/kubernetesio?ref_src=twsrc%5Etfw">@kubernetesio</a> YAML files?</p>&mdash; Matt Raible (@mraible) <a href="https://twitter.com/mraible/status/1387439868444397568?ref_src=twsrc%5Etfw">April 28, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
++++

TIP: Watch https://www.youtube.com/watch?v=cQAEK9PBY8U[Kubernetes Secrets in 5 Minutes] if you want to learn more about Kubernetes Secrets.

=== The Current State of Secret Management in Kubernetes

I recently noticed a tweet from https://twitter.com/daniel_bilar/status/1379845799086022661[Daniel Jacob Bilar] that links to a talk from FOSDEM 2021 on the https://fosdem.org/2021/schedule/event/kubernetes_secret_management/[current state of secret management within Kubernetes]. It's an excellent overview of the various options.

=== Google Cloud Secret Manager

Google Cloud has a https://spring-gcp.saturnism.me/app-dev/cloud-services/secret-management[Secret Manager] you can use to store your secrets. There's even a https://cloud.spring.io/spring-cloud-static/spring-cloud-gcp/current/reference/html/#secret-manager[Spring Boot starter] to make it convenient to retrieve these values in your app.

For example, you could store your database password in a properties file.

[source,properties]
----
spring.datasource.password=${sm://my-db-password}
----

This is pretty slick, but I like to remain cloud-agnostic. Also, I like how the JHipster Registry allows me to store encrypted secrets in Git.

=== Store Secrets in Git with Sealed Secrets and Kubeseal

https://bitnami.com/[Bitnami] has a https://github.com/bitnami-labs/sealed-secrets[Sealed Secrets] Apache-licensed open source project. Its README explains how it works.

> **Problem**: "I can manage all my K8s config in git, except Secrets."

> **Solution**: Encrypt your Secret into a SealedSecret, which is safe to store - even to a public repository. The SealedSecret can be decrypted only by the controller running in the target cluster and nobody else (not even the original author) is able to obtain the original Secret from the SealedSecret.

https://dev.to/stack-labs/store-your-kubernetes-secrets-in-git-thanks-to-kubeseal-hello-sealedsecret-2i6h[Store your Kubernetes Secrets in Git thanks to Kubeseal. Hello SealedSecret!] by https://twitter.com/aurelievache[Aur√©lie Vache] provides an excellent overview of how to use it.

First, you'll need to install the Sealed Secrets CRD (Custom Resource Definition).

[source,shell]
----
kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.16.0/controller.yaml
----

Retrieve the certificate keypair that's generated by this controller.

[source,shell]
----
kubectl get secret -n kube-system -l sealedsecrets.bitnami.com/sealed-secrets-key
----

You'll see output like the following:

[source,shell]
----
NAME                      TYPE                DATA   AGE
sealed-secrets-keypddlc   kubernetes.io/tls   2      2m
----

Run the following command with the name retrieved to get the `tls.crt` and `tls.key` data.

[source,shell]
----
kubectl get secret $NAME -o yaml -n kube-system
----

In this example, name should be `sealed-secrets-keypddlc`. Copy the raw value of `tls.cert` and decode it. You can use the command line:

[source,shell]
----
echo -n <paste-value-here> | base64 --decode
----

Or, an https://www.base64decode.org/[online base64 decoder].

Put the raw value in a `tls.cert` file.

TIP: You can also run `kubectl get pods -n kube-system`, get the name of the `sealed-secrets-controller`, and run `kubectl logs $NAME -n kube-system` to get the raw value of the certificate.

Next, install Kubeseal. On macOS, you can use Homebrew.

[source,shell]
----
brew install kubeseal
----

For other platforms, see https://github.com/bitnami-labs/sealed-secrets/releases/tag/v0.16.0[the release notes].

The major item you need to encrypt in this example is the `ENCRYPT_KEY` you used to encrypt the OIDC client secret. Run the following command to do this, where the key/value pair comes from your `docker-compose/.env` file.

[source,shell]
----
kubectl create secret generic encrypt-key --from-literal=ENCRYPT_KEY='your-value-here' \
  --dry-run=client -o yaml > secrets.yml
----

Next, use `kubeseal` to convert the secrets to encrypted secrets.

[source,shell]
----
kubeseal --cert tls.crt --format=yaml < secrets.yml > sealed-secrets.yml
----

Remove the original secrets file and deploy your sealed secrets.

[source,shell]
----
rm secrets.yml
kubectl apply -f sealed-secrets.yml

# verify it's been deployed
kubectl get sealedsecret
----

Now, remove all the OIDC variables you set in your `k8s/**/*-deployment.yml` files.

In `k8s/registry-k8s/jhipster-registry.yml`, add a number of `SPRING_CLOUD_CONFIG_SERVER_1_*` variables to point to GitHub and add the `ENCRYPT_KEY` that reads from the secret you created earlier. Make sure to adjust the GitHub repo to make one you created. As an alternative, you can put your OIDC settings in `k8s/registry-k8s/application-configmap.yml` if you'd rather not store your configuration in Git.

[source,yaml]
----
...
- name: SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_0_TYPE
  value: native
- name: SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_0_SEARCH_LOCATIONS
  value: file:./central-config
- name: SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_1_TYPE
  value: git
- name: SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_1_URI
  value: https://github.com/mraible/reactive-java-ms-config/
- name: SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_1_SEARCH_PATHS
  value: config
- name: SPRING_CLOUD_CONFIG_SERVER_COMPOSITE_1_LABEL
  value: main
- name: ENCRYPT_KEY
  valueFrom:
    secretKeyRef:
      name: encrypt-key
      key: ENCRYPT_KEY
----

Now, restart all your deployments.

[source,shell]
----
kubectl rollout restart deployment
----

You can use port-forwarding to see the JHipster Registry locally.

[source,shell]
----
kubectl port-forward jhipster-registry-0 8761:8761
----

To login, use `admin` with the `registry-admin-password` in `jhipster-registry.yml`.

image::{% asset_path 'blog/reactive-java-kubernetes/port-forwarded-registry.png' %}[alt=Port-forwarding the Registry to localhost,width=800,align=center]

=== Scale Your JHipster Microservices

You can scale your instances using the `kubectl scale` command.

[source,shell]
----
kubectl scale deployments/store --replicas=2
----

Scaling will work just fine for the microservice apps because they're set up as OAuth 2.0 resource servers, and are therefore stateless.

However, the gateway uses Spring Security's OIDC login feature and will store the access tokens in the session. If you scale it, session's won't be shared. Single sign-on should still work, you'll just have to do the OAuth dance to get tokens if you hit a different instance.

To synchronize sessions, you can use https://developer.okta.com/blog/2020/12/14/spring-session-redis[Spring Session and Redis] with JHipster.

[CAUTION]
====
If you leave everything running on Google Cloud, you will be charged for usage. I recommend removing your cluster, or scaling your instances to 0 to reduce your cost.

----
gcloud container clusters delete <cluster-name> --zone=us-central1-a
----
====

=== Spring Vault

Using an external key management solution like https://www.hashicorp.com/products/vault[HashiCorp Vault] is also recommended. The JHipster Registry doesn't have native support for Vault in its current release, but https://github.com/jhipster/jhipster-registry/issues/433[that could change soon].

In the meantime, I recommend reading https://developer.okta.com/blog/2020/05/04/spring-vault[Secure Secrets With Spring Cloud Config and Vault]

== Continuous Integration and Delivery of JHipster Microservices

This tutorial doesn't mention continuous integration and delivery of your reactive microservice architecture. I plan to cover that in a future post.

== Monitor Your Kubernetes Cluster with K9s and KDash

image::{% asset_path 'blog/reactive-java-kubernetes/k9s.png' %}[alt=K9s,role="BlogPost-avatar pull-right img-100px"]
Using `kubectl` to monitor your Kubernetes cluster can get tiresome. That's where https://github.com/derailed/k9s[K9s] can be useful. It provides a terminal UI to interact with your Kubernetes clusters. K9s was created by my good friend https://twitter.com/kitesurfer[Fernand Galiana]. He's also created a commercial version called https://k9salpha.io/[K9sAlpha].

There's also KDash, from JHipster co-lead, https://twitter.com/deepu105[Deepu K Sasidharan]. It's a simple K8s terminal dashboard built with Rust. Deepu recently https://twitter.com/deepu105/status/1383017556546584578[released an MVP of the project].

== Learn More About Java Microservices and Kubernetes

This blog post showed you how to deploy your reactive Java microservices to production using Kubernetes. JHipster did much of the heavy lifting for you since it generated all the YAML-based deployment descriptors. Since no one really likes writing YAML, I'm calling that a win!

You learned how to JHipster Registry to encrypt your secrets and configure Git as a configuration source. Bitnami's Sealed Secrets is a nice companion to encrypt the secrets in your Kubernetes deployment descriptors.

You can find the source code for this example on GitHub, in our https://github.com/oktadeveloper/java-microservices-examples[Java microservices examples repo].

[source,shell]
----
git clone https://github.com/oktadeveloper/java-microservices-examples.git
cd java-microservices-examples/jhipster-k8s
----

See JHipster's documentation on https://www.jhipster.tech/kubernetes/[Kubernetes] and https://www.jhipster.tech/gcp/[GCP] if you'd like more succinct instructions.

If you enjoyed this post, I think you'll like these others as well.

- https://developer.okta.com/blog/2021/01/20/reactive-java-microservices[Reactive Java Microservices with Spring Boot and JHipster]
- https://developer.okta.com/blog/2020/08/17/micronaut-jhipster-heroku[Build a Secure Micronaut and Angular App with JHipster]
- https://developer.okta.com/blog/2021/03/08/jhipster-quarkus-oidc[Fast Java Made Easy with Quarkus and JHipster]
- https://developer.okta.com/blog/2020/12/28/spring-boot-docker[How to Docker with Spring Boot]
- https://developer.okta.com/blog/2020/03/23/microservice-security-patterns[Security Patterns for Microservice Architectures]

If you have any questions, please ask them in the comments below.

To be notified when we publish new blog posts, follow us on https://twitter.com/oktadev[Twitter] or https://www.linkedin.com/company/oktadev[LinkedIn]. We frequently publish videos to our https://youtube.com/c/oktadev[YouTube channel] too. Please https://youtube.com/c/oktadev?sub_confirmation=1[subscribe]!
